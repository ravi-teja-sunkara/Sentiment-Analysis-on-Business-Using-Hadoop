{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from warcio.archiveiterator import ArchiveIterator\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(url):\n",
    "    urls=[]\n",
    "    resp = requests.get(url, stream=True)\n",
    "\n",
    "    for record in ArchiveIterator(resp.raw, arc2warc=True):\n",
    "        if record.rec_type == 'warcinfo':\n",
    "              continue\n",
    "\n",
    "        elif record.rec_type == 'response':\n",
    "            if record.http_headers.get_header('Content-Type') == 'text/html': #'used to txt/html\n",
    "                urls.append(record.rec_headers.get_header('WARC-Target-URI'))\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['business', 'money', 'markets', 'economy', 'entrepreneurship ', 'energy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wallstreet Journal: WARC-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url_1=[]\n",
    "url_1=get_urls('https://commoncrawl.s3.amazonaws.com/crawl-data/CC-MAIN-2019-13/segments/1552912201455.20/warc/CC-MAIN-20190318152343-20190318174343-00181.warc.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(url_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_1[0] = 'start'\n",
    "url_1 = url_1[1:len(url_1)]\n",
    "url_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_urls_1 = []\n",
    "for i in url_1:\n",
    "    if any(x in i for x in keywords):\n",
    "        related_urls_1.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(related_urls_1)\n",
    "# related_urls_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wallstreet Journal: WARC-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_2=[]\n",
    "url_2=get_urls('https://commoncrawl.s3.amazonaws.com/crawl-data/CC-MAIN-2019-13/segments/1552912201812.2/warc/CC-MAIN-20190318232014-20190319014014-00181.warc.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(url_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_2[0] = 'start'\n",
    "url_2 = url_2[1:len(url_2)]\n",
    "url_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_urls_2 = []\n",
    "for i in url_2:\n",
    "    if any(x in i for x in keywords):\n",
    "        related_urls_2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(related_urls_2))\n",
    "related_urls_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wallstreet Journal: WARC-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_3=[]\n",
    "url_3=get_urls('https://commoncrawl.s3.amazonaws.com/crawl-data/CC-MAIN-2019-13/segments/1552912204790.78/warc/CC-MAIN-20190326034712-20190326060712-00181.warc.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(url_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_3[0] = 'start'\n",
    "url_3 = url_3[1:len(url_3)]\n",
    "url_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_urls_3 = []\n",
    "for i in url_3:\n",
    "    if any(x in i for x in keywords):\n",
    "        related_urls_3.append(i)\n",
    "len(related_urls_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_url_wj=related_urls_1+related_urls_2+related_urls_3\n",
    "# print(final_url_wj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "# df = pandas.DataFrame(data={\"COMMON CRAWL URLS\": final_url_wj})\n",
    "# df.to_csv(\"cc_urls_wj.csv\", encoding='utf-8',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Wallstreet journal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_url_wj = pandas.read_csv(\"cc_urls_wj.csv\")\n",
    "final_url_wj.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article=''\n",
    "for i in range(1,len(final_url_wj)):\n",
    "#     print(i)\n",
    "    session = requests.Session()\n",
    "    url=final_url_wj['COMMON CRAWL URLS'][i]\n",
    "#     print(i)\n",
    "    req = session.get(url)\n",
    "    soup = BeautifulSoup(req.text)\n",
    "    paragraphs = soup.find_all('p')\n",
    "    for i in range(len(paragraphs)):\n",
    "        article = article + paragraphs[i].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cc_data_wj.txt\", \"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(\"%s\" % article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forbes: WARC-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_4=[]\n",
    "url_4=get_urls('https://commoncrawl.s3.amazonaws.com/crawl-data/CC-MAIN-2019-13/segments/1552912202188.9/warc/CC-MAIN-20190320004046-20190320030046-00018.warc.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(url_4))\n",
    "url_4[0] = 'start'\n",
    "url_4 = url_4[1:len(url_4)]\n",
    "url_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_urls_4 = []\n",
    "for i in url_4:\n",
    "    if any(x in i for x in keywords):\n",
    "        related_urls_4.append(i)\n",
    "len(related_urls_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forbes: WARC-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_5=[]\n",
    "url_5=get_urls('https://commoncrawl.s3.amazonaws.com/crawl-data/CC-MAIN-2019-13/segments/1552912202589.68/warc/CC-MAIN-20190322014319-20190322040319-00174.warc.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(url_5))\n",
    "url_5[0] = 'start'\n",
    "url_5 = url_5[1:len(url_5)]\n",
    "# print(url_5)\n",
    "related_urls_5 = []\n",
    "for i in url_5:\n",
    "    if any(x in i for x in keywords):\n",
    "        related_urls_5.append(i)\n",
    "len(related_urls_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(related_urls_5)\n",
    "print(related_urls_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forbes: WARC-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_6=[]\n",
    "url_6=get_urls('https://commoncrawl.s3.amazonaws.com/crawl-data/CC-MAIN-2019-13/segments/1552912202589.68/warc/CC-MAIN-20190322014319-20190322040319-00174.warc.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(url_6))\n",
    "url_6[0] = 'start'\n",
    "url_6 = url_6[1:len(url_6)]\n",
    "print(url_6)\n",
    "related_urls_6 = []\n",
    "for i in url_6:\n",
    "    if any(x in i for x in keywords):\n",
    "        related_urls_6.append(i)\n",
    "len(related_urls_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forbes: WARC-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_7=[]\n",
    "url_7=get_urls('https://commoncrawl.s3.amazonaws.com/crawl-data/CC-MAIN-2019-13/segments/1552912202698.22/warc/CC-MAIN-20190322220357-20190323002357-00174.warc.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(url_7))\n",
    "url_7[0] = 'start'\n",
    "url_7 = url_7[1:len(url_7)]\n",
    "print(url_7)\n",
    "related_urls_7 = []\n",
    "for i in url_7:\n",
    "    if any(x in i for x in keywords):\n",
    "        related_urls_7.append(i)\n",
    "len(related_urls_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forbes: WARC-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_8=[]\n",
    "url_8=get_urls('https://commoncrawl.s3.amazonaws.com/crawl-data/CC-MAIN-2019-13/segments/1552912202635.43/warc/CC-MAIN-20190322054710-20190322080710-00174.warc.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(url_8))\n",
    "url_8[0] = 'start'\n",
    "url_8 = url_8[1:len(url_8)]\n",
    "# print(url_8)\n",
    "related_urls_8 = []\n",
    "for i in url_8:\n",
    "    if any(x in i for x in keywords):\n",
    "        related_urls_8.append(i)\n",
    "len(related_urls_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_url_fb=related_urls_4+related_urls_5+related_urls_6+related_urls_7+related_urls_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "# df = pandas.DataFrame(data={\"COMMON CRAWL URLS\": final_url_fb})\n",
    "# df.to_csv(\"cc_urls_fb.csv\", encoding='utf-8',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forbes Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_url_fb = pandas.read_csv(\"cc_urls_fb.csv\")\n",
    "final_url_fb.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "article=''\n",
    "for i in range(1,len(final_url_fb)):\n",
    "#     print(i)\n",
    "    session = requests.Session()\n",
    "    url=final_url_fb['COMMON CRAWL URLS'][i]\n",
    "#     print(i)\n",
    "    req = session.get(url)\n",
    "    soup = BeautifulSoup(req.text)\n",
    "    paragraphs = soup.find_all('p')\n",
    "    for i in range(len(paragraphs)):\n",
    "        article = article + paragraphs[i].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cc_data_fb.txt\", \"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(\"%s\" % article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNBC: WARC-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_9=[]\n",
    "url_9=get_urls('https://commoncrawl.s3.amazonaws.com/crawl-data/CC-MAIN-2019-13/segments/1552912201707.53/crawldiagnostics/CC-MAIN-20190318211849-20190318233849-00392.warc.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(url_9))\n",
    "url_9[0] = 'start'\n",
    "url_9 = url_9[1:len(url_9)]\n",
    "# print(url_9)\n",
    "related_urls_9 = []\n",
    "for i in url_9:\n",
    "    if any(x in i for x in keywords):\n",
    "        related_urls_9.append(i)\n",
    "len(related_urls_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNBC: WARC-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_10=[]\n",
    "url_10=get_urls('https://commoncrawl.s3.amazonaws.com/crawl-data/CC-MAIN-2019-13/segments/1552912201707.53/warc/CC-MAIN-20190318211849-20190318233849-00057.warc.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(url_10))\n",
    "url_10[0] = 'start'\n",
    "url_10 = url_10[1:len(url_10)]\n",
    "# print(url_10)\n",
    "related_urls_10 = []\n",
    "for i in url_10:\n",
    "    if any(x in i for x in keywords):\n",
    "        related_urls_10.append(i)\n",
    "len(related_urls_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNBC: WARC-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_11=[]\n",
    "url_11=get_urls('https://commoncrawl.s3.amazonaws.com/crawl-data/CC-MAIN-2019-13/segments/1552912202704.58/warc/CC-MAIN-20190323000443-20190323022443-00057.warc.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(url_11))\n",
    "url_11[0] = 'start'\n",
    "url_11 = url_11[1:len(url_11)]\n",
    "# print(url_11)\n",
    "related_urls_11 = []\n",
    "for i in url_11:\n",
    "    if any(x in i for x in keywords):\n",
    "        related_urls_11.append(i)\n",
    "len(related_urls_11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNBC: WARC-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_12=[]\n",
    "url_12=get_urls('https://commoncrawl.s3.amazonaws.com/crawl-data/CC-MAIN-2019-13/segments/1552912202723.74/warc/CC-MAIN-20190323040640-20190323062640-00057.warc.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(url_12))\n",
    "url_12[0] = 'start'\n",
    "url_12 = url_12[1:len(url_12)]\n",
    "# print(url_12)\n",
    "related_urls_12 = []\n",
    "for i in url_12:\n",
    "    if any(x in i for x in keywords):\n",
    "        related_urls_12.append(i)\n",
    "len(related_urls_12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNBC: WARC-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_13=[]\n",
    "url_13=get_urls('https://commoncrawl.s3.amazonaws.com/crawl-data/CC-MAIN-2019-13/segments/1552912203378.92/warc/CC-MAIN-20190324063449-20190324085449-00057.warc.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(url_13))\n",
    "url_13[0] = 'start'\n",
    "url_13 = url_13[1:len(url_13)]\n",
    "# print(url_13)\n",
    "related_urls_13 = []\n",
    "for i in url_13:\n",
    "    if any(x in i for x in keywords):\n",
    "        related_urls_13.append(i)\n",
    "len(related_urls_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_url_cnbc=related_urls_9+related_urls_10+related_urls_11+related_urls_12+related_urls_13\n",
    "len(final_url_cnbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "# df = pandas.DataFrame(data={\"COMMON CRAWL URLS\": final_url_cnbc})\n",
    "# df.to_csv(\"cc_urls_cnbc.csv\", encoding='utf-8',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNBC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_url_cnbc = pandas.read_csv(\"cc_urls_cnbc.csv\")\n",
    "final_url_cnbc.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article=''\n",
    "for i in range(1,len(final_url_cnbc)):\n",
    "#     print(i)\n",
    "    session = requests.Session()\n",
    "    url=final_url_cnbc['COMMON CRAWL URLS'][i]\n",
    "#     print(url)\n",
    "    req = session.get(url)\n",
    "    soup = BeautifulSoup(req.text)\n",
    "    paragraphs = soup.find_all('p')\n",
    "    for i in range(len(paragraphs)):\n",
    "        article = article + paragraphs[i].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cc_data_cnbc.txt\", \"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(\"%s\" % article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN: WARC-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_14=[]\n",
    "url_14=get_urls('https://commoncrawl.s3.amazonaws.com/crawl-data/CC-MAIN-2019-13/segments/1552912201329.40/warc/CC-MAIN-20190318132220-20190318154220-00240.warc.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(url_14))\n",
    "url_14[0] = 'start'\n",
    "url_14 = url_14[1:len(url_14)]\n",
    "print(url_14)\n",
    "related_urls_14 = []\n",
    "for i in url_14:\n",
    "    if any(x in i for x in keywords):\n",
    "        related_urls_14.append(i)\n",
    "len(related_urls_14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN: WARC-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_15=[]\n",
    "url_15=get_urls('https://commoncrawl.s3.amazonaws.com/crawl-data/CC-MAIN-2019-13/segments/1552912201904.55/warc/CC-MAIN-20190319052517-20190319074517-00240.warc.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(url_15))\n",
    "url_15[0] = 'start'\n",
    "url_15 = url_15[1:len(url_15)]\n",
    "# print(url_15)\n",
    "related_urls_15 = []\n",
    "for i in url_15:\n",
    "    if any(x in i for x in keywords):\n",
    "        related_urls_15.append(i)\n",
    "len(related_urls_15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN: WARC-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_16=[]\n",
    "url_16=get_urls('https://commoncrawl.s3.amazonaws.com/crawl-data/CC-MAIN-2019-13/segments/1552912202303.66/warc/CC-MAIN-20190320064940-20190320090940-00240.warc.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(url_16))\n",
    "url_16[0] = 'start'\n",
    "url_16 = url_16[1:len(url_16)]\n",
    "# print(url_16)\n",
    "related_urls_16 = []\n",
    "for i in url_16:\n",
    "    if any(x in i for x in keywords):\n",
    "        related_urls_16.append(i)\n",
    "len(related_urls_16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN: WARC-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_17=[]\n",
    "url_17=get_urls('https://commoncrawl.s3.amazonaws.com/crawl-data/CC-MAIN-2019-13/segments/1552912202572.29/warc/CC-MAIN-20190321193403-20190321215403-00240.warc.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(url_17))\n",
    "url_17[0] = 'start'\n",
    "url_17 = url_17[1:len(url_17)]\n",
    "# print(url_17)\n",
    "related_urls_17 = []\n",
    "for i in url_17:\n",
    "    if any(x in i for x in keywords):\n",
    "        related_urls_17.append(i)\n",
    "len(related_urls_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_url_cnn=related_urls_14+related_urls_15+related_urls_16+related_urls_17\n",
    "len(final_url_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "# df = pandas.DataFrame(data={\"COMMON CRAWL URLS\": final_url_cnn})\n",
    "# df.to_cs\"cc_urls_cnn.csv\", encoding='utf-8',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_url_cnn = pandas.read_csv(\"cc_urls_cnn.csv\")\n",
    "final_url_cnn.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article=''\n",
    "for i in range(1,len(final_url_cnn)):\n",
    "#     print(i)\n",
    "    session = requests.Session()\n",
    "    url=final_url_cnn['COMMON CRAWL URLS'][i]\n",
    "#     print(url)\n",
    "    req = session.get(url)\n",
    "    soup = BeautifulSoup(req.text)\n",
    "    paragraphs = soup.find_all('p')\n",
    "    for i in range(len(paragraphs)):\n",
    "        article = article + paragraphs[i].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cc_data_cnn.txt\", \"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(\"%s\" % article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining text file into one text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "read_files = glob.glob(\"*.txt\")\n",
    "\n",
    "with open(\"final_cc.txt\", \"w\", encoding='utf-8') as outfile:\n",
    "    for f in read_files:\n",
    "        with open(f, \"r\", encoding='utf-8') as infile:\n",
    "            outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
